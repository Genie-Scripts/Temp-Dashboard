import warnings
warnings.filterwarnings('ignore', category=FutureWarning, module='pandas')
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import time
import hashlib
import gc
import logging
logger = logging.getLogger(__name__)
import traceback
from config import EXCLUDED_WARDS

# çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from unified_filters import (
    apply_unified_filters,
    get_unified_filter_summary,
    validate_unified_filters,
    get_unified_filter_config
)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils import safe_date_filter

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from alos_analysis_tab import display_alos_analysis_tab
    from dow_analysis_tab import display_dow_analysis_tab
    from individual_analysis_tab import display_individual_analysis_tab
    from forecast_analysis_tab import display_forecast_analysis_tab
    from forecast import generate_filtered_summaries
    from chart import (
        create_interactive_patient_chart,
        create_interactive_dual_axis_chart,
        create_forecast_comparison_chart
    )
    from pdf_generator import create_pdf, create_landscape_pdf
    from forecast import generate_filtered_summaries, create_forecast_dataframe
    from kpi_calculator import calculate_kpis, analyze_kpi_insights
    from utils import get_display_name_for_dept
except ImportError as e:
    st.error(f"å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    display_alos_analysis_tab = None
    display_dow_analysis_tab = None
    display_individual_analysis_tab = None
    display_forecast_analysis_tab = None
    create_interactive_patient_chart = None
    create_interactive_dual_axis_chart = None
    create_forecast_comparison_chart = None
    create_pdf = None
    create_landscape_pdf = None
    generate_filtered_summaries = None
    create_forecast_dataframe = None
    calculate_kpis = None
    analyze_kpi_insights = None
    get_display_name_for_dept = None

# ===============================================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ç¾¤ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰
# ===============================================================================
def create_detailed_analysis_tab():
    """
    è©³ç´°åˆ†æã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆå½¹å‰²å¤‰æ›´ã«ã‚ˆã‚Šå†…å®¹ã¯ç©ºã¾ãŸã¯å‰Šé™¤äºˆå®šï¼‰
    ã“ã®é–¢æ•°ã¯ app.py ã‹ã‚‰ã¯å‘¼ã³å‡ºã•ã‚Œãªããªã‚Šã¾ã™ã€‚
    å„åˆ†ææ©Ÿèƒ½ (ALOS, DOW, Individual) ã¯ app.py ã‹ã‚‰ç›´æ¥ã‚¿ãƒ–ã¨ã—ã¦å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
    """
    pass

def create_data_tables_tab():
    """ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    if not st.session_state.get('data_processed', False):
        st.warning("ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return

    df_original = st.session_state.get('df')
    if df_original is None or df_original.empty:
        st.error("åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    if get_unified_filter_config is None:
        st.error("çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚unified_filters.py ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    current_filter_config = get_unified_filter_config()

    df_filtered = apply_unified_filters(df_original)
    filter_summary = get_unified_filter_summary()
    st.info(f"ğŸ” çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ä¸­: {filter_summary}")

    if df_filtered.empty:
        st.warning("é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    ward_table_tab, dept_table_tab = st.tabs([
        "ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«",
        "ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"
    ])

    with ward_table_tab:
        create_ward_table_section(df_filtered)

    with dept_table_tab:
        create_department_table_section(df_filtered)

def create_individual_analysis_section(df_filtered, filter_config_from_caller):
    """å€‹åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    st.subheader("ğŸ” å€‹åˆ¥åˆ†æ")

    if display_individual_analysis_tab is None:
        st.warning("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚individual_analysis_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    if df_filtered is None or df_filtered.empty:
        st.warning("å€‹åˆ¥åˆ†æã®ãŸã‚ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        filter_summary = get_unified_filter_summary()
        st.info(f"ğŸ” é©ç”¨ä¸­ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {filter_summary}")
        return

    if generate_filtered_summaries and not df_filtered.empty:
        st.session_state.all_results = generate_filtered_summaries(df_filtered, None, None)
    elif df_filtered.empty:
        st.session_state.all_results = {"summary": pd.DataFrame(), "weekday": pd.DataFrame(), "holiday": pd.DataFrame(),
                                       "monthly_all":pd.DataFrame(), "monthly_weekday":pd.DataFrame(), "monthly_holiday":pd.DataFrame()}
    else:
        st.session_state.all_results = None

    if not df_filtered.empty and 'æ—¥ä»˜' in df_filtered.columns:
        st.session_state.latest_data_date_str = df_filtered['æ—¥ä»˜'].max().strftime("%Yå¹´%mæœˆ%dæ—¥")
    else:
        st.session_state.latest_data_date_str = st.session_state.get('latest_data_date_str', pd.Timestamp.now().strftime("%Yå¹´%mæœˆ%dæ—¥"))
        if df_filtered.empty:
             st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€æ—¥ä»˜æƒ…å ±ã¯ä¸æ­£ç¢ºã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚")

    st.session_state['unified_filter_applied'] = True

    original_all_results_backup = None
    if 'all_results' in st.session_state and st.session_state.all_results is not None:
        original_all_results_backup = st.session_state.all_results.copy() if isinstance(st.session_state.all_results, dict) else st.session_state.all_results

    original_latest_date_str_backup = st.session_state.get('latest_data_date_str')

    try:
        display_individual_analysis_tab(df_filtered)
    except Exception as e:
        logger.error(f"å€‹åˆ¥åˆ†æã‚¿ãƒ–ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        st.error(f"å€‹åˆ¥åˆ†æã‚¿ãƒ–ã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.info("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    finally:
        if original_all_results_backup is not None:
            st.session_state.all_results = original_all_results_backup
        if original_latest_date_str_backup is not None:
            st.session_state.latest_data_date_str = original_latest_date_str_backup

def create_ward_table_section(df_filtered):
    """ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆãƒ»è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ï¼‰"""
    st.subheader("ğŸ¥ ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        from utils import initialize_all_mappings, get_ward_display_name
        initialize_all_mappings(df_filtered, st.session_state.get('target_data'))
        ward_mapping = st.session_state.get('ward_mapping', {})
        
        if 'æ—¥ä»˜' in df_filtered.columns and not df_filtered['æ—¥ä»˜'].empty:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        ward_summary = calculate_ward_summary(df_filtered)
        if not ward_summary.empty:
            ward_summary['ç—…æ£Ÿå'] = ward_summary['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].apply(
                lambda x: get_ward_display_name(x, ward_mapping)
            )
            cols = ward_summary.columns.tolist()
            if 'ç—…æ£Ÿå' in cols and 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰' in cols:
                code_idx = cols.index('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰')
                cols.insert(code_idx + 1, cols.pop(cols.index('ç—…æ£Ÿå')))
                ward_summary = ward_summary[cols]
            
            # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾è¡¨ç¤ºï¼ˆè¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ï¼‰
            display_ward_table_simplified(ward_summary, df_filtered)
            create_ward_comparison_charts(ward_summary)
        else:
            st.warning("ç—…æ£Ÿåˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        st.error(f"ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def create_department_table_section(df_filtered):
    """è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œç‰ˆãƒ»è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ï¼‰"""
    st.subheader("ğŸ©º è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
    
    try:
        if df_filtered.empty:
            st.warning("æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        if 'æ—¥ä»˜' in df_filtered.columns and not df_filtered['æ—¥ä»˜'].empty:
            min_date = df_filtered['æ—¥ä»˜'].min().date()
            max_date = df_filtered['æ—¥ä»˜'].max().date()
            st.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
        
        dept_summary = calculate_department_summary(df_filtered)
        if not dept_summary.empty:
            if get_display_name_for_dept:
                dept_summary['è¨ºç™‚ç§‘è¡¨ç¤ºå'] = dept_summary['è¨ºç™‚ç§‘å'].apply(
                    lambda x: get_display_name_for_dept(x, default_name=x)
                )
                cols = dept_summary.columns.tolist()
                if 'è¨ºç™‚ç§‘è¡¨ç¤ºå' in cols and 'è¨ºç™‚ç§‘å' in cols:
                    name_idx = cols.index('è¨ºç™‚ç§‘å')
                    cols.insert(name_idx + 1, cols.pop(cols.index('è¨ºç™‚ç§‘è¡¨ç¤ºå')))
                    dept_summary = dept_summary[cols]
            
            # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾è¡¨ç¤ºï¼ˆè¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ï¼‰
            display_department_table_simplified(dept_summary, df_filtered)
            create_department_comparison_charts(dept_summary)
        else:
            st.warning("è¨ºç™‚ç§‘åˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        st.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def display_ward_table_simplified(ward_summary, df_filtered):
    """ç—…æ£Ÿåˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆè¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ç‰ˆï¼‰"""
    # ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½ã®ã¿æ®‹ã™
    col1, col2 = st.columns(2)
    with col1:
        sort_column = st.selectbox(
            "ä¸¦ã³æ›¿ãˆåŸºæº–", 
            options=['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'], 
            key="ward_table_sort_dt_simplified"
        )
    with col2:
        ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="ward_table_ascending_dt_simplified")
    
    display_summary = ward_summary.copy()
    if sort_column in display_summary.columns:
        display_summary = display_summary.sort_values(sort_column, ascending=ascending)
    
    format_dict = create_table_format_dict(display_summary)
    st.dataframe(
        display_summary.style.format(format_dict, na_rep='-'), 
        use_container_width=True, height=400
    )
    create_csv_download_button(display_summary, df_filtered, "ç—…æ£Ÿåˆ¥ãƒ‡ãƒ¼ã‚¿")

def display_department_table_simplified(dept_summary, df_filtered):
    """è¨ºç™‚ç§‘åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆè¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰Šé™¤ç‰ˆï¼‰"""
    # ä¸¦ã³æ›¿ãˆæ©Ÿèƒ½ã®ã¿æ®‹ã™
    col1, col2 = st.columns(2)
    with col1:
        sort_column = st.selectbox(
            "ä¸¦ã³æ›¿ãˆåŸºæº–", 
            options=['è¨ºç™‚ç§‘å', 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°'], 
            key="dept_table_sort_dt_simplified"
        )
    with col2:
        ascending = st.checkbox("æ˜‡é †ã§ä¸¦ã³æ›¿ãˆ", key="dept_table_ascending_dt_simplified")
    
    display_summary = dept_summary.copy()
    if sort_column in display_summary.columns:
        display_summary = display_summary.sort_values(sort_column, ascending=ascending)
    
    format_dict = create_table_format_dict(display_summary)
    st.dataframe(
        display_summary.style.format(format_dict, na_rep='-'), 
        use_container_width=True, height=400
    )
    create_csv_download_button(display_summary, df_filtered, "è¨ºç™‚ç§‘åˆ¥ãƒ‡ãƒ¼ã‚¿")

def create_table_format_dict(summary_df):
    """ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¾æ›¸ä½œæˆ"""
    format_dict = {}
    if summary_df is None or summary_df.empty: 
        return format_dict
    
    for col in summary_df.columns:
        if col in ['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'è¨ºç™‚ç§‘å', 'è¨ºç™‚ç§‘è¡¨ç¤ºå', 'ç—…æ£Ÿå', 'é›†è¨ˆå˜ä½']: 
            continue
        elif col in ['æœŸé–“æ—¥æ•°', 'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']:
            format_dict[col] = "{:,.0f}"
        elif col in ['å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 'å¹³å‡åœ¨é™¢æ—¥æ•°', 'ç—…åºŠå›è»¢ç‡']:
            format_dict[col] = "{:,.1f}"
        elif col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡ç‡', 'åœ¨é™¢æ‚£è€…æ•°å‰²åˆ', 'å…¥é™¢æ‚£è€…æ•°å‰²åˆ', 'é€€é™¢æ‚£è€…æ•°å‰²åˆ']:
            format_dict[col] = "{:.1f}%"
        else:
            if pd.api.types.is_numeric_dtype(summary_df[col]):
                if summary_df[col].dtype in ['int64', 'int32', 'Int64', 'Int32'] or (summary_df[col].dropna() % 1 == 0).all():
                    format_dict[col] = "{:,.0f}"
                else:
                    format_dict[col] = "{:,.1f}"
    return format_dict

def create_csv_download_button(summary_df, df_filtered, data_type):
    """CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ä½œæˆ"""
    csv_data = summary_df.to_csv(index=False).encode('utf-8-sig')
    period_str = "å…¨æœŸé–“"
    if 'æ—¥ä»˜' in df_filtered.columns and not df_filtered['æ—¥ä»˜'].empty:
        min_date = df_filtered['æ—¥ä»˜'].min().date()
        max_date = df_filtered['æ—¥ä»˜'].max().date()
        period_str = f"{min_date}_{max_date}"
    st.download_button(
        label=f"{data_type}ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data,
        file_name=f"{data_type}_{period_str}.csv", mime="text/csv",
        key=f"csv_download_btn_{data_type.replace(' ', '_')}"
    )

def calculate_ward_summary(df):
    """ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—"""
    try:
        # é™¤å¤–ç—…æ£Ÿã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰' in df.columns:
            df = df[~df['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].isin(EXCLUDED_WARDS)]

        required_cols = ['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'æ—¥ä»˜', 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']
        if not all(col in df.columns for col in required_cols):
            missing = [col for col in required_cols if col not in df.columns]
            logger.error(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing}")
            st.warning(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}ã€‚ä¸€éƒ¨æŒ‡æ¨™ãŒè¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            for m_col in missing:
                if m_col not in ['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'æ—¥ä»˜']: 
                    df[m_col] = 0

        ward_groups = df.groupby('ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', observed=True)
        ward_summary_data = {
            'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰': ward_groups['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].first(),
            'æœŸé–“æ—¥æ•°': ward_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': ward_groups['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰'].sum() if 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰' in df.columns else 0,
            'ç·å…¥é™¢æ‚£è€…æ•°': ward_groups['ç·å…¥é™¢æ‚£è€…æ•°'].sum() if 'ç·å…¥é™¢æ‚£è€…æ•°' in df.columns else 0,
            'ç·é€€é™¢æ‚£è€…æ•°': ward_groups['ç·é€€é™¢æ‚£è€…æ•°'].sum() if 'ç·é€€é™¢æ‚£è€…æ•°' in df.columns else 0,
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': ward_groups['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'].sum() if 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°' in df.columns else 0,
            'æ­»äº¡æ‚£è€…æ•°': ward_groups['æ­»äº¡æ‚£è€…æ•°'].sum() if 'æ­»äº¡æ‚£è€…æ•°' in df.columns else 0,
        }
        ward_summary = pd.DataFrame(ward_summary_data).reset_index(drop=True)
        
        ward_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = ward_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / row['æœŸé–“æ—¥æ•°'] if row['æœŸé–“æ—¥æ•°'] > 0 else 0, axis=1)
        ward_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = ward_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2) 
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0, axis=1)
        ward_summary['ç—…åºŠå›è»¢ç‡'] = ward_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        ward_summary['ç·Šæ€¥å…¥é™¢ç‡'] = ward_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100) if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        ward_summary['æ­»äº¡ç‡'] = ward_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100) if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        return ward_summary
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return pd.DataFrame()

def calculate_department_summary(df):
    """è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—"""
    try:
        required_cols = ['è¨ºç™‚ç§‘å', 'æ—¥ä»˜', 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰', 'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°']
        if not all(col in df.columns for col in required_cols):
            missing = [col for col in required_cols if col not in df.columns]
            logger.error(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing}")
            st.warning(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã«å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}ã€‚ä¸€éƒ¨æŒ‡æ¨™ãŒè¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
            for m_col in missing:
                if m_col not in ['è¨ºç™‚ç§‘å', 'æ—¥ä»˜']: 
                    df[m_col] = 0

        dept_groups = df.groupby('è¨ºç™‚ç§‘å', observed=True)
        dept_summary_data = {
            'è¨ºç™‚ç§‘å': dept_groups['è¨ºç™‚ç§‘å'].first(),
            'æœŸé–“æ—¥æ•°': dept_groups['æ—¥ä»˜'].nunique(),
            'å»¶ã¹åœ¨é™¢æ‚£è€…æ•°': dept_groups['å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰'].sum() if 'å…¥é™¢æ‚£è€…æ•°ï¼ˆåœ¨é™¢ï¼‰' in df.columns else 0,
            'ç·å…¥é™¢æ‚£è€…æ•°': dept_groups['ç·å…¥é™¢æ‚£è€…æ•°'].sum() if 'ç·å…¥é™¢æ‚£è€…æ•°' in df.columns else 0,
            'ç·é€€é™¢æ‚£è€…æ•°': dept_groups['ç·é€€é™¢æ‚£è€…æ•°'].sum() if 'ç·é€€é™¢æ‚£è€…æ•°' in df.columns else 0,
            'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°': dept_groups['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'].sum() if 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°' in df.columns else 0,
            'æ­»äº¡æ‚£è€…æ•°': dept_groups['æ­»äº¡æ‚£è€…æ•°'].sum() if 'æ­»äº¡æ‚£è€…æ•°' in df.columns else 0,
        }
        dept_summary = pd.DataFrame(dept_summary_data).reset_index(drop=True)
        
        dept_summary['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] = dept_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / row['æœŸé–“æ—¥æ•°'] if row['æœŸé–“æ—¥æ•°'] > 0 else 0, axis=1)
        dept_summary['å¹³å‡åœ¨é™¢æ—¥æ•°'] = dept_summary.apply(
            lambda row: row['å»¶ã¹åœ¨é™¢æ‚£è€…æ•°'] / ((row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) / 2) 
            if (row['ç·å…¥é™¢æ‚£è€…æ•°'] + row['ç·é€€é™¢æ‚£è€…æ•°']) > 0 else 0, axis=1)
        dept_summary['ç—…åºŠå›è»¢ç‡'] = dept_summary.apply(
            lambda row: row['ç·é€€é™¢æ‚£è€…æ•°'] / row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] if row['å¹³å‡åœ¨é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        dept_summary['ç·Šæ€¥å…¥é™¢ç‡'] = dept_summary.apply(
            lambda row: (row['ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°'] / row['ç·å…¥é™¢æ‚£è€…æ•°'] * 100) if row['ç·å…¥é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        dept_summary['æ­»äº¡ç‡'] = dept_summary.apply(
            lambda row: (row['æ­»äº¡æ‚£è€…æ•°'] / row['ç·é€€é™¢æ‚£è€…æ•°'] * 100) if row['ç·é€€é™¢æ‚£è€…æ•°'] > 0 else 0, axis=1)
        return dept_summary
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return pd.DataFrame()

def create_ward_comparison_charts(ward_summary):
    """ç—…æ£Ÿåˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•ä½œæˆ"""
    try:
        if ward_summary is None or ward_summary.empty:
            st.info("ç—…æ£Ÿåˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•: è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        st.markdown("---")
        st.subheader("ç—…æ£Ÿåˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        col1, col2 = st.columns(2)
        
        with col1:
            fig_census = px.bar(
                ward_summary, x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', y='å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°', color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 
                color_continuous_scale='Blues'
            )
            fig_census.update_layout(height=400)
            st.plotly_chart(fig_census, use_container_width=True)
        
        with col2:
            fig_alos = px.bar(
                ward_summary, x='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', y='å¹³å‡åœ¨é™¢æ—¥æ•°', 
                title='ç—…æ£Ÿåˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°', color='å¹³å‡åœ¨é™¢æ—¥æ•°', 
                color_continuous_scale='Reds'
            )
            fig_alos.update_layout(height=400)
            st.plotly_chart(fig_alos, use_container_width=True)
        
        fig_scatter = px.scatter(
            ward_summary, x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°', y='å¹³å‡åœ¨é™¢æ—¥æ•°', size='ç·å…¥é™¢æ‚£è€…æ•°',
            hover_name='ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', title='å¹³å‡åœ¨é™¢æ‚£è€…æ•° vs å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
            labels={'å¹³å‡åœ¨é™¢æ‚£è€…æ•°': 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆäººï¼‰', 'å¹³å‡åœ¨é™¢æ—¥æ•°': 'å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆæ—¥ï¼‰'}
        )
        fig_scatter.update_layout(height=400)
        st.plotly_chart(fig_scatter, use_container_width=True)
    except Exception as e:
        logger.error(f"ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        st.error(f"ç—…æ£Ÿåˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

def create_department_comparison_charts(dept_summary):
    """è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•ä½œæˆ"""
    try:
        if dept_summary is None or dept_summary.empty:
            st.info("è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•: è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        st.markdown("---")
        st.subheader("è¨ºç™‚ç§‘åˆ¥æ¯”è¼ƒã‚°ãƒ©ãƒ•")
        col1, col2 = st.columns(2)
        
        with col1:
            top_census = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°') if 'å¹³å‡åœ¨é™¢æ‚£è€…æ•°' in dept_summary.columns else pd.DataFrame()
            if not top_census.empty:
                fig_census = px.bar(
                    top_census, x='å¹³å‡åœ¨é™¢æ‚£è€…æ•°', y='è¨ºç™‚ç§‘å', orientation='h', 
                    title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ‚£è€…æ•°ï¼ˆä¸Šä½10ä½ï¼‰', color='å¹³å‡åœ¨é™¢æ‚£è€…æ•°', 
                    color_continuous_scale='Blues'
                )
                fig_census.update_layout(height=400)
                st.plotly_chart(fig_census, use_container_width=True)
            else: 
                st.caption("å¹³å‡åœ¨é™¢æ‚£è€…æ•°ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        with col2:
            top_alos = dept_summary.nlargest(10, 'å¹³å‡åœ¨é™¢æ—¥æ•°') if 'å¹³å‡åœ¨é™¢æ—¥æ•°' in dept_summary.columns else pd.DataFrame()
            if not top_alos.empty:
                fig_alos = px.bar(
                    top_alos, x='å¹³å‡åœ¨é™¢æ—¥æ•°', y='è¨ºç™‚ç§‘å', orientation='h', 
                    title='è¨ºç™‚ç§‘åˆ¥ å¹³å‡åœ¨é™¢æ—¥æ•°ï¼ˆä¸Šä½10ä½ï¼‰', color='å¹³å‡åœ¨é™¢æ—¥æ•°', 
                    color_continuous_scale='Reds'
                )
                fig_alos.update_layout(height=400)
                st.plotly_chart(fig_alos, use_container_width=True)
            else: 
                st.caption("å¹³å‡åœ¨é™¢æ—¥æ•°ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        if all(col in dept_summary.columns for col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡ç‡', 'ç·å…¥é™¢æ‚£è€…æ•°']):
            fig_rates = px.scatter(
                dept_summary, x='ç·Šæ€¥å…¥é™¢ç‡', y='æ­»äº¡ç‡', size='ç·å…¥é™¢æ‚£è€…æ•°',
                hover_name='è¨ºç™‚ç§‘å', title='ç·Šæ€¥å…¥é™¢ç‡ vs æ­»äº¡ç‡ï¼ˆãƒãƒ–ãƒ«ã‚µã‚¤ã‚ºï¼šç·å…¥é™¢æ‚£è€…æ•°ï¼‰',
                labels={'ç·Šæ€¥å…¥é™¢ç‡': 'ç·Šæ€¥å…¥é™¢ç‡ï¼ˆ%ï¼‰', 'æ­»äº¡ç‡': 'æ­»äº¡ç‡ï¼ˆ%ï¼‰'}
            )
            fig_rates.update_layout(height=400)
            st.plotly_chart(fig_rates, use_container_width=True)
        else:
            st.caption("ç·Šæ€¥å…¥é™¢ç‡ã€æ­»äº¡ç‡ã€ã¾ãŸã¯ç·å…¥é™¢æ‚£è€…æ•°ãƒ‡ãƒ¼ã‚¿ãªã—")
    except Exception as e:
        logger.error(f"è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        st.error(f"è¨ºç™‚ç§‘åˆ¥ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")