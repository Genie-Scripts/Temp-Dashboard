import streamlit as st
import pandas as pd
import numpy as np
import datetime
import traceback
from config import *

st.set_page_config(
    page_title=APP_TITLE,
    page_icon=APP_ICON,
    layout="wide",
    initial_sidebar_state="expanded"
)

from style import inject_global_css
from utils import initialize_all_mappings, logger # loggerã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

from data_persistence import (
    auto_load_data, save_data_to_file, load_data_from_file,
    get_data_info, delete_saved_data, get_file_sizes,
    save_settings_to_file, load_settings_from_file,
    get_backup_info, restore_from_backup
)

# --- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ---
# å¤‰æ•°ã®åˆæœŸåŒ–ï¼ˆé‡è¦ï¼šæœ€åˆã«å®šç¾©ï¼‰
FORECAST_AVAILABLE = False
DEPT_PERFORMANCE_AVAILABLE = False
WARD_PERFORMANCE_AVAILABLE = False

# analysis_tabs ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from analysis_tabs import create_data_tables_tab
except ImportError as e:
    logger.error(f"analysis_tabs.create_data_tables_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    create_data_tables_tab = lambda: st.error("ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

try:
    from analysis_tabs import create_individual_analysis_section
except ImportError as e:
    logger.error(f"analysis_tabs.create_individual_analysis_section ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    create_individual_analysis_section = lambda df_filtered, filter_config_from_caller: st.error("å€‹åˆ¥åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¿ãƒ–
try:
    from data_processing_tab import create_data_processing_tab
except ImportError as e:
    logger.error(f"data_processing_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    create_data_processing_tab = lambda: st.error("ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# PDFå‡ºåŠ›ã‚¿ãƒ–
try:
    import pdf_output_tab
except ImportError as e:
    logger.error(f"pdf_output_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    pdf_output_tab = type('pdf_output_tab_mock', (object,), {'create_pdf_output_tab': lambda: st.error("PDFå‡ºåŠ›æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")})()

# äºˆæ¸¬åˆ†æã‚¿ãƒ–
try:
    from forecast_analysis_tab import display_forecast_analysis_tab
    FORECAST_AVAILABLE = True
except ImportError as e:
    logger.error(f"forecast_analysis_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    display_forecast_analysis_tab = lambda: st.error("äºˆæ¸¬åˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    FORECAST_AVAILABLE = False

# KPIè¨ˆç®—æ©Ÿèƒ½
try:
    from kpi_calculator import calculate_kpis
except ImportError as e:
    logger.error(f"kpi_calculator ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    calculate_kpis = None

# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ¦‚è¦ã‚¿ãƒ–
try:
    from dashboard_overview_tab import display_kpi_cards_only
except ImportError as e:
    logger.error(f"dashboard_overview_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    display_kpi_cards_only = lambda *args, **kwargs: st.error("çµŒå–¶ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰KPIè¡¨ç¤ºæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# çµ±åˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½
try:
    from unified_filters import (create_unified_filter_sidebar, apply_unified_filters,
                                 get_unified_filter_summary, initialize_unified_filters,
                                 get_unified_filter_config, validate_unified_filters)
except ImportError as e:
    logger.error(f"unified_filters ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    create_unified_filter_sidebar = lambda df: None
    apply_unified_filters = lambda df: df
    get_unified_filter_summary = lambda: "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±å–å¾—ä¸å¯"
    initialize_unified_filters = lambda df: None
    get_unified_filter_config = lambda: {}
    validate_unified_filters = lambda df: (False, "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œè¨¼æ©Ÿèƒ½åˆ©ç”¨ä¸å¯")

# å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã‚¿ãƒ–
try:
    from alos_analysis_tab import display_alos_analysis_tab
except ImportError as e:
    logger.error(f"alos_analysis_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    display_alos_analysis_tab = lambda df_filtered_by_period, start_date_ts, end_date_ts, common_config=None: st.error("å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æã‚¿ãƒ–
try:
    from dow_analysis_tab import display_dow_analysis_tab
except ImportError as e:
    logger.error(f"dow_analysis_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    display_dow_analysis_tab = lambda df, start_date, end_date, common_config=None: st.error("æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# å€‹åˆ¥åˆ†æã‚¿ãƒ–
try:
    from individual_analysis_tab import display_individual_analysis_tab
except ImportError as e:
    logger.error(f"individual_analysis_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    display_individual_analysis_tab = lambda df_filtered_main: st.error("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¿ãƒ–
try:
    from department_performance_tab import create_department_performance_tab
    DEPT_PERFORMANCE_AVAILABLE = True
except ImportError as e:
    logger.error(f"department_performance_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    DEPT_PERFORMANCE_AVAILABLE = False
    create_department_performance_tab = lambda: st.error("è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¿ãƒ–
try:
    from ward_performance_tab import create_ward_performance_tab
    WARD_PERFORMANCE_AVAILABLE = True
except ImportError as e:
    logger.error(f"ward_performance_tab ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    WARD_PERFORMANCE_AVAILABLE = False
    create_ward_performance_tab = lambda: st.error("ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# ä¿®æ­£ç®‡æ‰€ï¼šGitHub Publisherã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨å‘¼ã³å‡ºã—ã‚’create_sidebarã«é›†ç´„
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
def get_analysis_period():
    if not st.session_state.get('data_processed', False):
        return None, None, "ãƒ‡ãƒ¼ã‚¿æœªå‡¦ç†"
    filter_config = get_unified_filter_config()
    if filter_config and 'start_date' in filter_config and 'end_date' in filter_config:
        start_date_ts = pd.Timestamp(filter_config['start_date']).normalize()
        end_date_ts = pd.Timestamp(filter_config['end_date']).normalize()
        if filter_config.get('period_mode') == "ãƒ—ãƒªã‚»ãƒƒãƒˆæœŸé–“" and filter_config.get('preset'):
            period_description = filter_config['preset']
        else:
            period_description = f"{start_date_ts.strftime('%Y/%m/%d')}ï½{end_date_ts.strftime('%Y/%m/%d')}"
        return start_date_ts, end_date_ts, period_description
    else:
        df = st.session_state.get('df')
        if df is not None and not df.empty and 'æ—¥ä»˜' in df.columns:
            latest_date = df['æ—¥ä»˜'].max()
            default_start_ts = (latest_date - pd.Timedelta(days=29)).normalize()
            return default_start_ts, latest_date.normalize(), "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœŸé–“ (ç›´è¿‘30æ—¥)"
        return None, None, "æœŸé–“æœªè¨­å®š"

def filter_data_by_analysis_period(df_original):
    if df_original is None or df_original.empty:
        return pd.DataFrame()
    return apply_unified_filters(df_original)

def check_forecast_dependencies():
    missing_libs = []
    try: import statsmodels
    except ImportError: missing_libs.append("statsmodels")
    try: import pmdarima
    except ImportError: missing_libs.append("pmdarima")
    if missing_libs:
        st.sidebar.warning(
            f"äºˆæ¸¬æ©Ÿèƒ½ã®å®Œå…¨ãªå‹•ä½œã«ã¯ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™:\n"
            f"{', '.join(missing_libs)}\n\n"
            f"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•:\n```\npip install {' '.join(missing_libs)}\n```"
        )
    return len(missing_libs) == 0

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆé–¢æ•°ã®å®šç¾© (create_sidebar ã‚ˆã‚Šå‰ã«å®šç¾©) ---
def create_sidebar_data_settings():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‡ãƒ¼ã‚¿è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹å¼·åŒ–ç‰ˆï¼‰"""
    st.sidebar.header("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿è¨­å®š")
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³è¡¨ç¤ºï¼ˆå¼·åŒ–ç‰ˆï¼‰
    with st.sidebar.expander("ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³", expanded=True):
        if st.session_state.get('data_processed', False):
            df = st.session_state.get('df')
            if df is not None:
                data_source = st.session_state.get('data_source', 'unknown')
                latest_date_str = st.session_state.get('latest_data_date_str', 'ä¸æ˜')
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ¸ˆã¿")
                st.write(f"ğŸ“… æœ€æ–°æ—¥ä»˜: {latest_date_str}")
                st.write(f"ğŸ“Š ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}ä»¶")
                
                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¡¨ç¤ºï¼ˆå¼·åŒ–ï¼‰
                source_text = {
                    'auto_loaded': 'è‡ªå‹•èª­ã¿è¾¼ã¿', 
                    'manual_loaded': 'æ‰‹å‹•èª­ã¿è¾¼ã¿', 
                    'sidebar_upload': 'ã‚µã‚¤ãƒ‰ãƒãƒ¼',
                    'data_processing_tab': 'ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã‚¿ãƒ–',
                    'incremental_add': 'è¿½åŠ èª­ã¿è¾¼ã¿',
                    'unknown': 'ä¸æ˜'
                }.get(data_source, 'ä¸æ˜')
                st.write(f"ğŸ”„ èª­ã¿è¾¼ã¿å…ƒ: {source_text}")
                
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ï¼ˆæ–°è¦è¿½åŠ ï¼‰
                if 'æ—¥ä»˜' in df.columns and not df['æ—¥ä»˜'].empty:
                    min_date = df['æ—¥ä»˜'].min()
                    max_date = df['æ—¥ä»˜'].max()
                    period_days = (max_date - min_date).days + 1
                    st.write(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {period_days}æ—¥é–“")
                    st.caption(f"{min_date.strftime('%Y/%m/%d')} ï½ {max_date.strftime('%Y/%m/%d')}")
                
                data_info = get_data_info()
                if data_info:
                    last_saved = data_info.get('last_saved', 'ä¸æ˜')
                    if last_saved != 'ä¸æ˜':
                        try:
                            saved_date = datetime.datetime.fromisoformat(last_saved.replace('Z', '+00:00'))
                            formatted_date = saved_date.strftime('%Y/%m/%d %H:%M')
                            st.write(f"ğŸ’¾ æœ€çµ‚ä¿å­˜: {formatted_date}")
                        except:
                            st.write(f"ğŸ’¾ æœ€çµ‚ä¿å­˜: {last_saved}")
                else:
                    st.warning("âš ï¸ æœªä¿å­˜ãƒ‡ãƒ¼ã‚¿")
            else:
                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼")
        else:
            st.info("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿æœªèª­ã¿è¾¼ã¿")
            data_info = get_data_info()
            if data_info:
                st.write("ğŸ’¾ ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š")
                # ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æƒ…å ±ï¼ˆæ–°è¦è¿½åŠ ï¼‰
                try:
                    st.caption(f"ğŸ“Š {data_info.get('data_rows', 0):,}ä»¶")
                    if data_info.get('file_size_mb'):
                        st.caption(f"ğŸ“ {data_info['file_size_mb']} MB")
                    
                    # æ—¥ä»˜ç¯„å›²æƒ…å ±
                    date_range = data_info.get('date_range', {})
                    if date_range.get('min_date') and date_range.get('max_date'):
                        min_dt = datetime.datetime.fromisoformat(date_range['min_date'])
                        max_dt = datetime.datetime.fromisoformat(date_range['max_date'])
                        st.caption(f"ğŸ“… {min_dt.strftime('%Y/%m/%d')} ï½ {max_dt.strftime('%Y/%m/%d')}")
                except Exception:
                    pass
                
                if st.button("ğŸ”„ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="load_saved_data_sidebar_enhanced_v2", use_container_width=True):
                    df_loaded, target_data_loaded, metadata_loaded = load_data_from_file()
                    if df_loaded is not None:
                        st.session_state['df'] = df_loaded
                        st.session_state['target_data'] = target_data_loaded
                        st.session_state['data_processed'] = True
                        st.session_state['data_source'] = 'manual_loaded'
                        st.session_state['data_metadata'] = metadata_loaded
                        if 'æ—¥ä»˜' in df_loaded.columns and not df_loaded['æ—¥ä»˜'].empty:
                            latest_date = df_loaded['æ—¥ä»˜'].max()
                            st.session_state.latest_data_date_str = latest_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                        else:
                            st.session_state.latest_data_date_str = "æ—¥ä»˜ä¸æ˜"
                        initialize_all_mappings(st.session_state.df, st.session_state.target_data)
                        st.rerun()

    # ãƒ‡ãƒ¼ã‚¿æ“ä½œï¼ˆå¼·åŒ–ç‰ˆï¼‰
    with st.sidebar.expander("ğŸ”§ ãƒ‡ãƒ¼ã‚¿æ“ä½œ", expanded=False):
        # åŸºæœ¬æ“ä½œï¼ˆä¿å­˜ãƒ»èª­è¾¼ï¼‰
        st.markdown("**ğŸ“ åŸºæœ¬æ“ä½œ**")
        col1_ds, col2_ds = st.columns(2)
        
        with col1_ds:
            if st.button("ğŸ’¾ ä¿å­˜", key="save_current_data_sidebar_enhanced_v2", use_container_width=True):
                if st.session_state.get('data_processed', False):
                    df_to_save = st.session_state.get('df')
                    target_data_to_save = st.session_state.get('target_data')
                    
                    # ä¿å­˜æ™‚ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    enhanced_metadata = {
                        'save_timestamp': datetime.datetime.now().isoformat(),
                        'data_source': st.session_state.get('data_source', 'unknown'),
                        'processing_info': st.session_state.get('performance_metrics', {}),
                        'filter_state': st.session_state.get('current_unified_filter_config', {}),
                    }
                    
                    if save_data_to_file(df_to_save, target_data_to_save, enhanced_metadata):
                        st.success("âœ… ä¿å­˜å®Œäº†!")
                        st.rerun()
                    else:
                        st.error("âŒ ä¿å­˜å¤±æ•—")
                else:
                    st.warning("ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        with col2_ds:
            if st.button("ğŸ“¥ èª­è¾¼", key="load_saved_data_manual_v2", use_container_width=True):
                df_loaded, target_data_loaded, metadata_loaded = load_data_from_file()
                if df_loaded is not None:
                    st.session_state['df'] = df_loaded
                    st.session_state['target_data'] = target_data_loaded
                    st.session_state['data_processed'] = True
                    st.session_state['data_source'] = 'manual_loaded'
                    st.session_state['data_metadata'] = metadata_loaded
                    
                    if 'æ—¥ä»˜' in df_loaded.columns and not df_loaded['æ—¥ä»˜'].empty:
                        latest_date = df_loaded['æ—¥ä»˜'].max()
                        st.session_state.latest_data_date_str = latest_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                    else:
                        st.session_state.latest_data_date_str = "æ—¥ä»˜ä¸æ˜"
                    
                    initialize_all_mappings(st.session_state.df, st.session_state.target_data)
                    if st.session_state.df is not None and not st.session_state.df.empty:
                        initialize_unified_filters(st.session_state.df)
                    
                    st.success("âœ… èª­è¾¼å®Œäº†!")
                    st.rerun()
                else:
                    st.error("âŒ èª­è¾¼å¤±æ•—")

        # è¿½åŠ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ©Ÿèƒ½ï¼ˆæ–°è¦ï¼‰
        if st.session_state.get('data_processed', False):
            st.markdown("---")
            st.markdown("**â• è¿½åŠ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿**")
            st.caption("ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ")
            
            additional_file = st.file_uploader(
                "è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«", 
                type=["xlsx", "xls", "csv"], 
                key="additional_data_upload_sidebar_v2",
                help="ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«"
            )
            
            if additional_file is not None:
                col_mode, col_exec = st.columns(2)
                
                with col_mode:
                    merge_mode = st.selectbox(
                        "çµåˆæ–¹å¼",
                        ["è¿½åŠ ", "æ›´æ–°"],
                        key="merge_mode_sidebar_v2",
                        help="è¿½åŠ : å˜ç´”çµåˆã€æ›´æ–°: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿æ›´æ–°"
                    )
                
                with col_exec:
                    if st.button("ğŸ”„ å®Ÿè¡Œ", key="execute_additional_load_sidebar_v2", use_container_width=True):
                        try:
                            # è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
                            if additional_file.name.endswith('.csv'):
                                df_additional = pd.read_csv(additional_file, encoding='utf-8')
                            else:
                                df_additional = pd.read_excel(additional_file)
                            
                            # æ—¥ä»˜åˆ—ã®æ­£è¦åŒ–
                            if 'æ—¥ä»˜' in df_additional.columns:
                                df_additional['æ—¥ä»˜'] = pd.to_datetime(df_additional['æ—¥ä»˜'], errors='coerce').dt.normalize()
                                df_additional.dropna(subset=['æ—¥ä»˜'], inplace=True)
                            
                            current_df = st.session_state.get('df')
                            combined_df = None  # åˆæœŸåŒ–
                            
                            if merge_mode == "è¿½åŠ ":
                                combined_df = pd.concat([current_df, df_additional], ignore_index=True)
                                combined_df.drop_duplicates(inplace=True)
                                
                            elif merge_mode == "æ›´æ–°":
                                if all(col in df_additional.columns for col in ['æ—¥ä»˜', 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'è¨ºç™‚ç§‘å']):
                                    merge_keys = ['æ—¥ä»˜', 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'è¨ºç™‚ç§‘å']
                                    df_additional_keys = df_additional[merge_keys].drop_duplicates()
                                    
                                    mask = current_df.set_index(merge_keys).index.isin(
                                        df_additional_keys.set_index(merge_keys).index
                                    )
                                    df_remaining = current_df[~mask].reset_index(drop=True)
                                    combined_df = pd.concat([df_remaining, df_additional], ignore_index=True)
                                else:
                                    st.error("æ›´æ–°ãƒ¢ãƒ¼ãƒ‰ã«ã¯æ—¥ä»˜ã€ç—…æ£Ÿã‚³ãƒ¼ãƒ‰ã€è¨ºç™‚ç§‘åã®åˆ—ãŒå¿…è¦ã§ã™")
                                    combined_df = None
                            
                            # æ­£å¸¸ã«çµåˆã§ããŸå ´åˆã®ã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                            if combined_df is not None:
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°
                                st.session_state['df'] = combined_df
                                st.session_state['data_source'] = 'incremental_add'
                                
                                if 'æ—¥ä»˜' in combined_df.columns and not combined_df['æ—¥ä»˜'].empty:
                                    latest_date = combined_df['æ—¥ä»˜'].max()
                                    st.session_state.latest_data_date_str = latest_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                                
                                # ãƒãƒƒãƒ”ãƒ³ã‚°ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®å†åˆæœŸåŒ–
                                initialize_all_mappings(st.session_state.df, st.session_state.target_data)
                                initialize_unified_filters(st.session_state.df)
                                
                                st.success(f"âœ… {merge_mode}å®Œäº†! ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(combined_df):,}ä»¶")
                                st.rerun()
                            
                        except Exception as e:
                            st.error(f"âŒ è¿½åŠ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

        # ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆå¼·åŒ–ç‰ˆï¼‰
        st.markdown("---")
        st.markdown("**ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ**")
        
        col_reset1, col_reset2 = st.columns(2)
        
        with col_reset1:
            if st.button("ğŸ”„ ã‚»ãƒƒã‚·ãƒ§ãƒ³\nã‚¯ãƒªã‚¢", key="reset_session_sidebar_v2", use_container_width=True):
                keys_to_clear = [
                    'df', 'target_data', 'data_processed', 'data_source', 'data_metadata',
                    'latest_data_date_str', 'all_results', 'current_unified_filter_config',
                    'mappings_initialized_after_processing', 'unified_filter_initialized',
                    'validation_results', 'performance_metrics'
                ]
                for key in keys_to_clear:
                    if key in st.session_state:
                        del st.session_state[key]
                
                st.success("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªã‚¢å®Œäº†")
                st.info("ğŸ’¾ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã¯ç¶­æŒã•ã‚Œã¦ã„ã¾ã™")
                st.rerun()
        
        with col_reset2:
            if st.button("ğŸ—‘ï¸ å®Œå…¨\nå‰Šé™¤", key="delete_all_data_sidebar_v2", use_container_width=True):
                if st.session_state.get('confirm_delete_ready', False):
                    success, result = delete_saved_data()
                    if success:
                        st.success("âœ… å®Œå…¨å‰Šé™¤å®Œäº†")
                        keys_to_clear = [
                            'df', 'target_data', 'data_processed', 'data_source', 'data_metadata',
                            'latest_data_date_str', 'all_results', 'current_unified_filter_config',
                            'mappings_initialized_after_processing', 'unified_filter_initialized',
                            'validation_results', 'performance_metrics', 'confirm_delete_ready'
                        ]
                        for key in keys_to_clear:
                            if key in st.session_state:
                                del st.session_state[key]
                        st.rerun()
                    else:
                        st.error(f"âŒ å‰Šé™¤å¤±æ•—: {result}")
                else:
                    st.session_state['confirm_delete_ready'] = True
                    st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã§å®Œå…¨å‰Šé™¤")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæƒ…å ±
        file_sizes = get_file_sizes()
        if any(size != "æœªä¿å­˜" for size in file_sizes.values()):
            st.markdown("---")
            st.markdown("**ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:**")
            for name, size in file_sizes.items():
                if size != "æœªä¿å­˜":
                    st.caption(f"â€¢ {name}: {size}")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ + å¼·åŒ–ï¼‰
    with st.sidebar.expander("ğŸ—‚ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†", expanded=False):
        backup_info = get_backup_info()
        if backup_info:
            st.write("ğŸ“‹ **åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:**")
            for backup in backup_info:
                col1_bk, col2_bk = st.columns([3, 1])
                with col1_bk:
                    st.write(f"ğŸ“„ {backup['timestamp']}")
                    st.caption(f"ã‚µã‚¤ã‚º: {backup['size']}")
                    # çµŒéæ—¥æ•°è¡¨ç¤ºï¼ˆæ–°è¦è¿½åŠ ï¼‰
                    if backup.get('age_days', 0) == 0:
                        st.caption("ğŸ“… ä»Šæ—¥ä½œæˆ")
                    else:
                        st.caption(f"ğŸ“… {backup['age_days']}æ—¥å‰")
                with col2_bk:
                    if st.button("å¾©å…ƒ", key=f"restore_{backup['filename']}_sidebar_enhanced_v2", use_container_width=True):
                        success, message = restore_from_backup(backup['filename'])
                        if success:
                            st.success(message)
                            st.info("ğŸ”„ ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦å¾©å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                            st.rerun()
                        else:
                            st.error(message)
        else:
            st.info("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
            st.caption("ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã¨è‡ªå‹•çš„ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒä½œæˆã•ã‚Œã¾ã™")
        
        # æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
        st.markdown("---")
        if st.button("ğŸ“¦ æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ", key="create_manual_backup_sidebar_v2", use_container_width=True):
            if st.session_state.get('data_processed', False):
                from data_persistence import create_backup
                if create_backup(force_create=True):
                    st.success("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†")
                    st.rerun()
                else:
                    st.error("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå¤±æ•—")
            else:
                st.warning("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    # ç°¡æ˜“ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ—¢å­˜æ©Ÿèƒ½ã‚’å¼·åŒ–ï¼‰
    with st.sidebar.expander("ğŸ“¤ ç°¡æ˜“ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=False):
        st.write("**ç°¡æ˜“çš„ãªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿**")
        st.caption("è©³ç´°ãªå‡¦ç†ã¯ã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‚¿ãƒ–ã‚’ä½¿ç”¨")
        uploaded_file_sidebar = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=SUPPORTED_FILE_TYPES, key="sidebar_file_upload_widget_enhanced_v2",
            help="Excel/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
        )
        if uploaded_file_sidebar is not None:
            col_simple1, col_simple2 = st.columns(2)
            
            with col_simple1:
                replace_mode = st.radio(
                    "èª­ã¿è¾¼ã¿æ–¹å¼",
                    ["æ–°è¦", "è¿½åŠ "],
                    key="simple_upload_mode_sidebar_v2",
                    help="æ–°è¦: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç½®æ›ã€è¿½åŠ : æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ "
                )
            
            with col_simple2:
                if st.button("âš¡ å®Ÿè¡Œ", key="quick_process_sidebar_enhanced_v2", use_container_width=True):
                    try:
                        if uploaded_file_sidebar.name.endswith('.csv'):
                            df_uploaded = pd.read_csv(uploaded_file_sidebar, encoding='utf-8')
                        else:
                            df_uploaded = pd.read_excel(uploaded_file_sidebar)

                        if 'æ—¥ä»˜' in df_uploaded.columns:
                            df_uploaded['æ—¥ä»˜'] = pd.to_datetime(df_uploaded['æ—¥ä»˜'], errors='coerce').dt.normalize()
                            df_uploaded.dropna(subset=['æ—¥ä»˜'], inplace=True)

                        if replace_mode == "æ–°è¦" or not st.session_state.get('data_processed', False):
                            st.session_state['df'] = df_uploaded
                            st.session_state['data_source'] = 'sidebar_upload'
                        else:
                            current_df = st.session_state.get('df')
                            combined_df = pd.concat([current_df, df_uploaded], ignore_index=True)
                            combined_df.drop_duplicates(inplace=True)
                            st.session_state['df'] = combined_df
                            st.session_state['data_source'] = 'incremental_add'

                        st.session_state['data_processed'] = True
                        st.session_state['target_data'] = None
                        
                        if 'æ—¥ä»˜' in st.session_state['df'].columns and not st.session_state['df']['æ—¥ä»˜'].empty:
                            latest_date = st.session_state['df']['æ—¥ä»˜'].max()
                            st.session_state.latest_data_date_str = latest_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                        else:
                            st.session_state.latest_data_date_str = "æ—¥ä»˜ä¸æ˜"
                        
                        initialize_all_mappings(st.session_state.df, None)
                        initialize_unified_filters(st.session_state.df)
                        st.session_state.mappings_initialized_after_processing = True
                        
                        st.success(f"âœ… {replace_mode}èª­ã¿è¾¼ã¿å®Œäº†!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def create_sidebar_target_file_status():
    """ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ³ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    if st.session_state.get('target_data') is not None:
        st.sidebar.markdown("---") # ä»–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã®åŒºåˆ‡ã‚Š
        st.sidebar.subheader("ğŸ¯ ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ³")
        st.sidebar.success("âœ… ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿")
        extracted_targets = st.session_state.get('extracted_targets')
        if extracted_targets:
            if extracted_targets.get('target_days') or extracted_targets.get('target_admissions'):
                st.sidebar.markdown("###### <span style='color:green;'>ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—:</span>", unsafe_allow_html=True)
                if extracted_targets.get('target_days'):
                    st.sidebar.write(f"- å»¶ã¹åœ¨é™¢æ—¥æ•°ç›®æ¨™: {extracted_targets['target_days']:,.0f}äººæ—¥")
                if extracted_targets.get('target_admissions'):
                    st.sidebar.write(f"- æ–°å…¥é™¢æ‚£è€…æ•°ç›®æ¨™: {extracted_targets['target_admissions']:,.0f}äºº")
                if extracted_targets.get('used_pattern'):
                    st.sidebar.caption(f"æ¤œç´¢æ¡ä»¶: {extracted_targets['used_pattern']}")
            else:
                st.sidebar.warning("âš ï¸ ç›®æ¨™å€¤ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        if st.sidebar.checkbox("ğŸ” ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ç¢ºèª", key="sidebar_show_target_details_app_v2"): # ã‚­ãƒ¼å¤‰æ›´
            target_data_disp = st.session_state.get('target_data')
            if target_data_disp is not None:
                st.sidebar.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:** {target_data_disp.shape[0]}è¡Œ Ã— {target_data_disp.shape[1]}åˆ—")
                st.sidebar.write("**åˆ—å:**", list(target_data_disp.columns))
                st.sidebar.dataframe(target_data_disp.head(), use_container_width=True)
                debug_info_disp = st.session_state.get('target_file_debug_info')
                if debug_info_disp and debug_info_disp.get('search_results'):
                    st.sidebar.markdown("###### **æ¤œç´¢çµæœè©³ç´°:**")
                    for keyword, results in debug_info_disp['search_results'].items():
                        if results:
                            st.sidebar.write(f"ã€Œ{keyword}ã€ã®æ¤œç´¢çµæœ:")
                            for result_item in results:
                                st.sidebar.write(f"  - {result_item['column']}: {result_item['matches']}ä»¶")
                        else:
                            st.sidebar.write(f"ã€Œ{keyword}ã€: è©²å½“ãªã—")

def create_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®šUIï¼ˆGitHubè‡ªå‹•å…¬é–‹æ©Ÿèƒ½ã®å‘¼ã³å‡ºã—ã‚’ã“ã“ã«é›†ç´„ï¼‰"""

    # 1. åˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    st.sidebar.header("ğŸ” åˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    if st.session_state.get('data_processed', False) and st.session_state.get('df') is not None:
        df_for_filter_init = st.session_state.get('df')
        if not df_for_filter_init.empty:
            initialize_unified_filters(df_for_filter_init)
            st.session_state['current_unified_filter_config'] = create_unified_filter_sidebar(df_for_filter_init)
    else:
        st.sidebar.info("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã¨åˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    st.sidebar.markdown("---")

    # 2. ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šï¼ˆè¨­å®šå€¤åˆæœŸåŒ–ã‚’å¼·åŒ–ï¼‰
    st.sidebar.header("âš™ï¸ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š")
    
    # è¨­å®šå€¤ã®åˆæœŸåŒ–ï¼ˆconfig.pyã‹ã‚‰ã®èª­ã¿è¾¼ã¿å¼·åŒ–ï¼‰
    if 'settings_initialized' not in st.session_state:
        # config.pyã‹ã‚‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–
        st.session_state.total_beds = DEFAULT_TOTAL_BEDS
        st.session_state.bed_occupancy_rate = DEFAULT_OCCUPANCY_RATE
        st.session_state.bed_occupancy_rate_percent = int(DEFAULT_OCCUPANCY_RATE * 100)
        st.session_state.avg_length_of_stay = DEFAULT_AVG_LENGTH_OF_STAY
        st.session_state.avg_admission_fee = DEFAULT_ADMISSION_FEE
        st.session_state.monthly_target_patient_days = DEFAULT_TARGET_PATIENT_DAYS
        st.session_state.monthly_target_admissions = DEFAULT_TARGET_ADMISSIONS
        
        # ä¿å­˜ã•ã‚ŒãŸè¨­å®šãŒã‚ã‚Œã°ä¸Šæ›¸ã
        saved_settings = load_settings_from_file()
        if saved_settings:
            for key, value in saved_settings.items():
                if key in st.session_state:  # æ—¢å­˜ã®ã‚­ãƒ¼ã®ã¿æ›´æ–°
                    st.session_state[key] = value
        
        st.session_state.settings_initialized = True
    
    with st.sidebar.expander("ğŸ¥ åŸºæœ¬ç—…é™¢è¨­å®š", expanded=False):
        def get_safe_value(key, default, value_type=int):
            value = st.session_state.get(key, default)
            if isinstance(value, list): 
                value = value[0] if value else default
            elif not isinstance(value, (int, float)): 
                value = default
            return value_type(value)

        total_beds = st.number_input(
            "ç·ç—…åºŠæ•°", 
            min_value=HOSPITAL_SETTINGS['min_beds'], 
            max_value=HOSPITAL_SETTINGS['max_beds'],
            value=get_safe_value('total_beds', DEFAULT_TOTAL_BEDS), 
            step=1, 
            help="ç—…é™¢ã®ç·ç—…åºŠæ•°",
            key="sidebar_total_beds_global_v4"
        )
        st.session_state.total_beds = total_beds
        
        current_occupancy_percent = st.session_state.get('bed_occupancy_rate_percent', int(DEFAULT_OCCUPANCY_RATE * 100))
        bed_occupancy_rate = st.slider(
            "ç›®æ¨™ç—…åºŠç¨¼åƒç‡ (%)", 
            min_value=int(HOSPITAL_SETTINGS['min_occupancy_rate'] * 100),
            max_value=int(HOSPITAL_SETTINGS['max_occupancy_rate'] * 100),
            value=current_occupancy_percent, 
            step=1, 
            help="ç›®æ¨™ã¨ã™ã‚‹ç—…åºŠç¨¼åƒç‡",
            key="sidebar_bed_occupancy_rate_slider_global_v4"
        ) / 100
        st.session_state.bed_occupancy_rate = bed_occupancy_rate
        st.session_state.bed_occupancy_rate_percent = int(bed_occupancy_rate * 100)
        
        avg_length_of_stay = st.number_input(
            "å¹³å‡åœ¨é™¢æ—¥æ•°ç›®æ¨™", 
            min_value=HOSPITAL_SETTINGS['min_avg_stay'], 
            max_value=HOSPITAL_SETTINGS['max_avg_stay'],
            value=get_safe_value('avg_length_of_stay', DEFAULT_AVG_LENGTH_OF_STAY, float), 
            step=0.1, 
            help="ç›®æ¨™ã¨ã™ã‚‹å¹³å‡åœ¨é™¢æ—¥æ•°",
            key="sidebar_avg_length_of_stay_global_v4"
        )
        st.session_state.avg_length_of_stay = avg_length_of_stay
        
        avg_admission_fee = st.number_input(
            "å¹³å‡å…¥é™¢æ–™ï¼ˆå††/æ—¥ï¼‰", 
            min_value=1000, 
            max_value=100000,
            value=get_safe_value('avg_admission_fee', DEFAULT_ADMISSION_FEE), 
            step=1000, 
            help="1æ—¥ã‚ãŸã‚Šã®å¹³å‡å…¥é™¢æ–™",
            key="sidebar_avg_admission_fee_global_v4"
        )
        st.session_state.avg_admission_fee = avg_admission_fee

    with st.sidebar.expander("ğŸ¯ KPIç›®æ¨™å€¤è¨­å®š", expanded=False):
        monthly_target_patient_days = st.number_input(
            "æœˆé–“å»¶ã¹åœ¨é™¢æ—¥æ•°ç›®æ¨™ï¼ˆäººæ—¥ï¼‰", 
            min_value=100, 
            max_value=50000,
            value=get_safe_value('monthly_target_patient_days', DEFAULT_TARGET_PATIENT_DAYS), 
            step=100, 
            help="æœˆé–“ã®å»¶ã¹åœ¨é™¢æ—¥æ•°ç›®æ¨™",
            key="sidebar_monthly_target_pd_global_v4"
        )
        st.session_state.monthly_target_patient_days = monthly_target_patient_days
        
        monthly_target_admissions = st.number_input(
            "æœˆé–“æ–°å…¥é™¢æ‚£è€…æ•°ç›®æ¨™ï¼ˆäººï¼‰", 
            min_value=10, 
            max_value=5000,
            value=get_safe_value('monthly_target_admissions', DEFAULT_TARGET_ADMISSIONS), 
            step=10, 
            help="æœˆé–“ã®æ–°å…¥é™¢æ‚£è€…æ•°ç›®æ¨™",
            key="sidebar_monthly_target_adm_global_v4"
        )
        st.session_state.monthly_target_admissions = monthly_target_admissions

    if st.sidebar.button("ğŸ’¾ ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã¨KPIç›®æ¨™å€¤ã‚’ä¿å­˜", key="save_all_global_settings_sidebar_v5", use_container_width=True):
        settings_to_save = {
            'total_beds': st.session_state.total_beds,
            'bed_occupancy_rate': st.session_state.bed_occupancy_rate,
            'bed_occupancy_rate_percent': st.session_state.bed_occupancy_rate_percent,
            'avg_length_of_stay': st.session_state.avg_length_of_stay,
            'avg_admission_fee': st.session_state.avg_admission_fee,
            'monthly_target_patient_days': st.session_state.monthly_target_patient_days,
            'monthly_target_admissions': st.session_state.monthly_target_admissions
        }
        if save_settings_to_file(settings_to_save):
            st.sidebar.success("è¨­å®šä¿å­˜å®Œäº†!")
        else:
            st.sidebar.error("è¨­å®šä¿å­˜å¤±æ•—")
    
    # ç¾åœ¨ã®è¨­å®šå€¤ç¢ºèª
    with st.sidebar.expander("ğŸ“‹ ç¾åœ¨ã®è¨­å®šå€¤ç¢ºèª", expanded=False):
        st.markdown("**ğŸ¥ åŸºæœ¬è¨­å®š**")
        st.write(f"â€¢ ç·ç—…åºŠæ•°: {st.session_state.get('total_beds', DEFAULT_TOTAL_BEDS)}åºŠ")
        st.write(f"â€¢ ç›®æ¨™ç—…åºŠç¨¼åƒç‡: {st.session_state.get('bed_occupancy_rate', DEFAULT_OCCUPANCY_RATE)*100:.1f}%")
        st.write(f"â€¢ ç›®æ¨™å¹³å‡åœ¨é™¢æ—¥æ•°: {st.session_state.get('avg_length_of_stay', DEFAULT_AVG_LENGTH_OF_STAY):.1f}æ—¥")
        st.write(f"â€¢ å¹³å‡å…¥é™¢æ–™: {st.session_state.get('avg_admission_fee', DEFAULT_ADMISSION_FEE):,}å††/æ—¥")
        
        st.markdown("**ğŸ¯ KPIç›®æ¨™å€¤**")
        st.write(f"â€¢ æœˆé–“å»¶ã¹åœ¨é™¢æ—¥æ•°ç›®æ¨™: {st.session_state.get('monthly_target_patient_days', DEFAULT_TARGET_PATIENT_DAYS):,}äººæ—¥")
        st.write(f"â€¢ æœˆé–“æ–°å…¥é™¢æ‚£è€…æ•°ç›®æ¨™: {st.session_state.get('monthly_target_admissions', DEFAULT_TARGET_ADMISSIONS):,}äºº")
        
        # è¨ˆç®—å€¤ã‚‚è¡¨ç¤º
        st.markdown("**ğŸ“Š è¨ˆç®—å€¤**")
        target_daily_census = st.session_state.get('total_beds', DEFAULT_TOTAL_BEDS) * st.session_state.get('bed_occupancy_rate', DEFAULT_OCCUPANCY_RATE)
        target_daily_admissions = st.session_state.get('monthly_target_admissions', DEFAULT_TARGET_ADMISSIONS) / 30
        st.write(f"â€¢ ç›®æ¨™æ—¥å¹³å‡åœ¨é™¢æ‚£è€…æ•°: {target_daily_census:.1f}äºº")
        st.write(f"â€¢ ç›®æ¨™æ—¥å¹³å‡æ–°å…¥é™¢æ‚£è€…æ•°: {target_daily_admissions:.1f}äºº/æ—¥")
    
    st.sidebar.markdown("---")

    # 3. ãƒ‡ãƒ¼ã‚¿è¨­å®š
    create_sidebar_data_settings()
    st.sidebar.markdown("---")

    # 4. ç›®æ¨™å€¤ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ³
    create_sidebar_target_file_status()
    try:
        from github_publisher import create_github_publisher_interface
        create_github_publisher_interface() # ã“ã®å‘¼ã³å‡ºã—ä¸€æœ¬ã«çµã‚‹
        
        # === ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½ã®çŠ¶æ³ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ ===
        try:
            from html_export_functions import calculate_all_high_scores
            logger.info("âœ… ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½: ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        except ImportError:
            logger.info("âš ï¸ ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½: ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            logger.error(f"âš ï¸ ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½: ã‚¨ãƒ©ãƒ¼ - {e}")
            
    except ImportError as e:
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸŒ çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å…¬é–‹")
        st.sidebar.error("è‡ªå‹•å…¬é–‹æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        st.sidebar.info("å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«(github_publisher.pyãªã©)ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        logger.error(f"GitHub Publisher Import Error: {e}", exc_info=True)
    except Exception as e:
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸŒ çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å…¬é–‹")
        st.sidebar.error(f"è‡ªå‹•å…¬é–‹æ©Ÿèƒ½ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½ã®å®Ÿè£…çŠ¶æ³ã‚‚è¡¨ç¤º
        st.sidebar.caption("ğŸ† ãƒã‚¤ã‚¹ã‚³ã‚¢æ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")
        logger.error(f"GitHub Publisher Unexpected Error: {e}", exc_info=True)
    
    return True

def create_management_dashboard_tab():
    st.header("ğŸ“Š ä¸»è¦æŒ‡æ¨™")
    
    if not st.session_state.get('data_processed', False) or st.session_state.get('df') is None:
        st.warning("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿å¾Œã«åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")
        return
    
    df_original = st.session_state.get('df')
    start_date_ts, end_date_ts, period_description = get_analysis_period()
    
    if start_date_ts is None or end_date_ts is None:
        st.error("åˆ†ææœŸé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ã§æœŸé–“ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    df_for_dashboard = filter_data_by_analysis_period(df_original)
    
    if df_for_dashboard.empty:
        st.warning("é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«åˆè‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    total_beds = st.session_state.get('total_beds', 500)
    target_occupancy_rate_percent = st.session_state.get('bed_occupancy_rate', 0.85) * 100
    
    # ===========================================
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆï¼ˆå³ä¸Šã«å°ã•ãé…ç½®ï¼‰
    # ===========================================
    col_main, col_debug = st.columns([4, 1])
    with col_debug:
        debug_mode = st.checkbox(
            "ãƒ‡ãƒãƒƒã‚°æƒ…å ±", 
            value=False, 
            key="dashboard_debug_mode",
            help="è©³ç´°ãªå‡¦ç†æƒ…å ±ã‚’è¡¨ç¤º"
        )
    
    # ===========================================
    # KPIã‚«ãƒ¼ãƒ‰è¡¨ç¤ºï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
    # ===========================================
    if display_kpi_cards_only:
        try:
            # show_debugãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            import inspect
            sig = inspect.signature(display_kpi_cards_only)
            if 'show_debug' in sig.parameters:
                display_kpi_cards_only(
                    df_for_dashboard, start_date_ts, end_date_ts, 
                    total_beds, target_occupancy_rate_percent,
                    show_debug=debug_mode
                )
            else:
                display_kpi_cards_only(
                    df_for_dashboard, start_date_ts, end_date_ts, 
                    total_beds, target_occupancy_rate_percent
                )
        except Exception as e:
            st.error(f"KPIã‚«ãƒ¼ãƒ‰è¡¨ç¤ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            if debug_mode:
                st.text(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
                try:
                    sig = inspect.signature(display_kpi_cards_only)
                    st.text(f"åˆ©ç”¨å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {list(sig.parameters.keys())}")
                except:
                    st.text("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“")
    else:
        st.error("KPIã‚«ãƒ¼ãƒ‰è¡¨ç¤ºæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚dashboard_overview_tab.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    # ===========================================
    # ç°¡æ½”ãªåˆ†ææ¡ä»¶è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹æ™‚ã®ã¿ï¼‰
    # ===========================================
    if not debug_mode:
        st.markdown("---")
        
        col_period, col_records, col_target = st.columns(3)
        
        with col_period:
            date_range_days = (end_date_ts - start_date_ts).days + 1
            st.metric(
                "ğŸ“Š åˆ†ææœŸé–“", 
                f"{date_range_days}æ—¥é–“",
                f"{start_date_ts.strftime('%Y/%m/%d')} ï½ {end_date_ts.strftime('%Y/%m/%d')}"
            )
        
        with col_records:
            record_count = len(df_for_dashboard)
            st.metric("ğŸ“‹ åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{record_count:,}ä»¶")
        
        with col_target:
            target_data = st.session_state.get('target_data')
            if target_data is not None and not target_data.empty:
                target_records = len(target_data)
                st.metric("ğŸ¯ ç›®æ¨™å€¤ãƒ‡ãƒ¼ã‚¿", f"{target_records}è¡Œ", "ä½¿ç”¨ä¸­")
            else:
                st.metric("ğŸ¯ ç›®æ¨™å€¤ãƒ‡ãƒ¼ã‚¿", "æœªè¨­å®š", "")
        
        st.caption("â€» æœŸé–“å¤‰æ›´ã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œåˆ†æãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ã§è¡Œãˆã¾ã™")

def main():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'app_initialized' not in st.session_state:
        st.session_state.app_initialized = True
    if 'data_processed' not in st.session_state: 
        st.session_state['data_processed'] = False
    if 'df' not in st.session_state: 
        st.session_state['df'] = None
    if 'forecast_model_results' not in st.session_state: 
        st.session_state.forecast_model_results = {}
    if 'mappings_initialized_after_processing' not in st.session_state: 
        st.session_state.mappings_initialized_after_processing = False

    # è¨­å®šå€¤ã®åˆæœŸåŒ–
    if 'global_settings_initialized' not in st.session_state:
        st.session_state.total_beds = DEFAULT_TOTAL_BEDS
        st.session_state.bed_occupancy_rate = DEFAULT_OCCUPANCY_RATE
        st.session_state.bed_occupancy_rate_percent = int(DEFAULT_OCCUPANCY_RATE * 100)
        st.session_state.avg_length_of_stay = DEFAULT_AVG_LENGTH_OF_STAY
        st.session_state.avg_admission_fee = DEFAULT_ADMISSION_FEE
        st.session_state.monthly_target_patient_days = DEFAULT_TARGET_PATIENT_DAYS
        st.session_state.monthly_target_admissions = DEFAULT_TARGET_ADMISSIONS
        st.session_state.global_settings_initialized = True

    # è‡ªå‹•èª­ã¿è¾¼ã¿
    try:
        auto_loaded = auto_load_data()
        if auto_loaded and st.session_state.get('df') is not None:
            st.success("âœ… ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ")
            if 'target_data' not in st.session_state: 
                st.session_state.target_data = None
            initialize_all_mappings(st.session_state.df, st.session_state.target_data)
            if st.session_state.df is not None and not st.session_state.df.empty:
                initialize_unified_filters(st.session_state.df)
            st.session_state.mappings_initialized_after_processing = True
    except Exception as e:
        st.error(f"è‡ªå‹•èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    # ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown(f'<h1 class="main-header">{APP_ICON} {APP_TITLE}</h1>', unsafe_allow_html=True)
    
    # ----------- ã“ã“ã‹ã‚‰ã‚¿ãƒ–UIâ†’ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³å‹ã«åˆ‡æ›¿ -----------

    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®å®šç¾©ï¼ˆäºˆæ¸¬åˆ†æã®æœ‰ç„¡ã‚‚è€ƒæ…®ï¼‰
    menu_options = [
        "ğŸ“Š ä¸»è¦æŒ‡æ¨™", "ğŸ¥ è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹", "ğŸ¨ ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
        "ğŸ—“ï¸ å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ", "ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ", "ğŸ” å€‹åˆ¥åˆ†æ"
    ]
    if FORECAST_AVAILABLE:
        menu_options.append("ğŸ”® äºˆæ¸¬åˆ†æ")
    menu_options.extend(["ğŸ“¤ ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›", "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›"])

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã§é¸æŠ
    selected_menu = st.sidebar.selectbox("ç”»é¢é¸æŠ", menu_options, index=0)

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ä½œæˆ
    create_sidebar()
    
    # ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ç”»é¢
    if selected_menu == "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›":
        try:
            create_data_processing_tab()
            if st.session_state.get('data_processed') and st.session_state.get('df') is not None:
                if not st.session_state.get('df').empty:
                    initialize_unified_filters(st.session_state.df)
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã‚¿ãƒ–ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")

    # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
    elif st.session_state.get('data_processed', False) and st.session_state.get('df') is not None:
        df_original_main = st.session_state.get('df')
        common_config_main = st.session_state.get('common_config', {})
        df_filtered_unified = filter_data_by_analysis_period(df_original_main)
        current_filter_config = get_unified_filter_config()

        if selected_menu == "ğŸ“Š ä¸»è¦æŒ‡æ¨™":
            try: 
                create_management_dashboard_tab()
            except Exception as e: 
                st.error(f"ä¸»è¦æŒ‡æ¨™ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ¥ è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹":
            try:
                if DEPT_PERFORMANCE_AVAILABLE:
                    create_department_performance_tab()
                else:
                    st.error("è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.error(f"è¨ºç™‚ç§‘åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ¨ ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹":
            try:
                if WARD_PERFORMANCE_AVAILABLE:
                    create_ward_performance_tab()
                else:
                    st.error("ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            except Exception as e:
                st.error(f"ç—…æ£Ÿåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ—“ï¸ å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ":
            try:
                if display_alos_analysis_tab:
                    start_dt, end_dt, _ = get_analysis_period()
                    if start_dt and end_dt:
                         display_alos_analysis_tab(df_filtered_unified, start_dt, end_dt, common_config_main)
                    else: 
                        st.warning("å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æ: åˆ†ææœŸé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else: 
                    st.error("å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            except Exception as e: 
                st.error(f"å¹³å‡åœ¨é™¢æ—¥æ•°åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ“… æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ":
            try:
                if display_dow_analysis_tab:
                    start_dt, end_dt, _ = get_analysis_period()
                    if start_dt and end_dt:
                        display_dow_analysis_tab(df_filtered_unified, start_dt, end_dt, common_config_main)
                    else: 
                        st.warning("æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ: åˆ†ææœŸé–“ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else: 
                    st.error("æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            except Exception as e: 
                st.error(f"æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ” å€‹åˆ¥åˆ†æ":
            try:
                if create_individual_analysis_section:
                    create_individual_analysis_section(df_filtered_unified, current_filter_config)
                else: 
                    st.error("å€‹åˆ¥åˆ†ææ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            except Exception as e: 
                st.error(f"å€‹åˆ¥åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ”® äºˆæ¸¬åˆ†æ" and FORECAST_AVAILABLE:
            try:
                deps_ok = check_forecast_dependencies()
                if deps_ok:
                    original_df_for_forecast = st.session_state.get('df')
                    st.session_state['df'] = df_filtered_unified
                    display_forecast_analysis_tab()
                    st.session_state['df'] = original_df_for_forecast
                else: 
                    st.info("äºˆæ¸¬åˆ†æã«ã¯è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚")
            except Exception as e: 
                st.error(f"äºˆæ¸¬åˆ†æã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
        elif selected_menu == "ğŸ“¤ ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›":
            st.header("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›")
            output_sub_tab1, output_sub_tab2 = st.tabs(["ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«", "ğŸ“„ PDFå‡ºåŠ›"])
            with output_sub_tab1:
                try: 
                    if callable(create_data_tables_tab):
                        create_data_tables_tab()
                    else:
                        st.error("ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
                except Exception as e: 
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    if debug_mode:  # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è©³ç´°è¡¨ç¤º
                        st.text(traceback.format_exc())
            with output_sub_tab2:
                try: 
                    pdf_output_tab.create_pdf_output_tab()
                except Exception as e: 
                    st.error(f"PDFå‡ºåŠ›æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼: {str(e)}\n{traceback.format_exc()}")
    else:
        # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆ
        if selected_menu != "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å…¥åŠ›":
            st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿å¾Œã«åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")
            data_info = get_data_info()
            if data_info: 
                st.info("ğŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ãƒ‡ãƒ¼ã‚¿ä»¶æ•°", f"{data_info.get('data_rows', 0):,}ä»¶")
                with col2:
                    if data_info.get('file_size_mb'):
                        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{data_info['file_size_mb']} MB")
                with col3:
                    if data_info.get('last_saved'):
                        try:
                            saved_date = datetime.datetime.fromisoformat(data_info['last_saved'].replace('Z', '+00:00'))
                            st.metric("æœ€çµ‚ä¿å­˜", saved_date.strftime('%m/%d %H:%M'))
                        except:
                            st.metric("æœ€çµ‚ä¿å­˜", "ä¸æ˜")
                col_load1, col_load2 = st.columns(2)
                with col_load1:
                    if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key=f"quick_load_tab_{selected_menu}", use_container_width=True):
                        df_loaded, target_data_loaded, metadata_loaded = load_data_from_file()
                        if df_loaded is not None:
                            st.session_state['df'] = df_loaded
                            st.session_state['target_data'] = target_data_loaded
                            st.session_state['data_processed'] = True
                            st.session_state['data_source'] = 'manual_loaded'
                            st.session_state['data_metadata'] = metadata_loaded
                            if 'æ—¥ä»˜' in df_loaded.columns and not df_loaded['æ—¥ä»˜'].empty:
                                latest_date = df_loaded['æ—¥ä»˜'].max()
                                st.session_state.latest_data_date_str = latest_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                            else:
                                st.session_state.latest_data_date_str = "æ—¥ä»˜ä¸æ˜"
                            initialize_all_mappings(st.session_state.df, st.session_state.target_data)
                            if st.session_state.df is not None and not st.session_state.df.empty:
                                initialize_unified_filters(st.session_state.df)
                            st.session_state.mappings_initialized_after_processing = True
                            st.success("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†!")
                            st.rerun()
                        else:
                            st.error("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                with col_load2:
                    st.caption("ã¾ãŸã¯ã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            else: 
                st.info("ğŸ“‹ ã€Œãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã€ã‚¿ãƒ–ã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        f'<div style="text-align: center; color: #666666; font-size: 0.8rem;">'
        f'{APP_ICON} {APP_TITLE} | {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        f'</div>',
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()