# dow_analysis_tab.py (ä¿®æ­£ç‰ˆ - çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨)
import streamlit as st
import pandas as pd
import numpy as np
import logging
from config import EXCLUDED_WARDS
logger = logging.getLogger(__name__)

# dow_charts.py ã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (å¤‰æ›´ãªã—)
try:
    from dow_charts import (
        get_dow_data,
        create_dow_chart,
        calculate_dow_summary,
        create_dow_heatmap,
        DOW_LABELS
    )
    DOW_CHARTS_AVAILABLE = True
except ImportError as e:
    logger.error(f"dow_charts.py ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    DOW_CHARTS_AVAILABLE = False
    get_dow_data = lambda *args, **kwargs: pd.DataFrame()
    create_dow_chart = lambda *args, **kwargs: None
    calculate_dow_summary = lambda *args, **kwargs: pd.DataFrame()
    create_dow_heatmap = lambda *args, **kwargs: None
    DOW_LABELS = ['æœˆæ›œæ—¥', 'ç«æ›œæ—¥', 'æ°´æ›œæ—¥', 'æœ¨æ›œæ—¥', 'é‡‘æ›œæ—¥', 'åœŸæ›œæ—¥', 'æ—¥æ›œæ—¥']

def display_dow_analysis_tab(
    df: pd.DataFrame,
    start_date, # Timestampæƒ³å®š
    end_date,   # Timestampæƒ³å®š
    common_config=None # ç¾çŠ¶æœªä½¿ç”¨ã ãŒã€å°†æ¥çš„ãªå…±é€šè¨­å®šã®ãŸã‚ã«æ®‹ã™
):
    """
    æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æã‚¿ãƒ–ã®è¡¨ç¤ºé–¢æ•°ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨ç‰ˆï¼‰
    Args:
        df (pd.DataFrame): çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§æ—¢ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ã®DataFrame
        start_date (pd.Timestamp): åˆ†ææœŸé–“ã®é–‹å§‹æ—¥
        end_date (pd.Timestamp): åˆ†ææœŸé–“ã®çµ‚äº†æ—¥
        common_config (dict, optional): å…±é€šè¨­å®š
    """
    logger.info("æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æã‚¿ãƒ–ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆçµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨ç‰ˆï¼‰")

    st.header("ğŸ“† æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ")

    if df is None or df.empty:
        st.warning("ğŸ” åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    required_cols = [
        'æ—¥ä»˜', 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰', 'è¨ºç™‚ç§‘å',
        'ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°',
        'å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°', 'åœ¨é™¢æ‚£è€…æ•°'
    ]
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        st.error(f"âŒ æ›œæ—¥åˆ¥åˆ†æã«å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_cols)}")
        logger.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {missing_cols}")
        return

    # 'å¹³æ—¥åˆ¤å®š' åˆ—ã®ç¢ºèªã¨è¿½åŠ 
    df_analysis = df.copy()
    if 'ç—…æ£Ÿã‚³ãƒ¼ãƒ‰' in df_analysis.columns and EXCLUDED_WARDS:
        df_analysis = df_analysis[~df_analysis['ç—…æ£Ÿã‚³ãƒ¼ãƒ‰'].isin(EXCLUDED_WARDS)]
    if 'å¹³æ—¥åˆ¤å®š' not in df_analysis.columns:
        try:
            import jpholiday
            def is_holiday_for_dow(date_val):
                return (
                    date_val.weekday() >= 5 or
                    jpholiday.is_holiday(date_val) or
                    (date_val.month == 12 and date_val.day >= 29) or
                    (date_val.month == 1 and date_val.day <= 3)
                )
            df_analysis['å¹³æ—¥åˆ¤å®š'] = pd.to_datetime(df_analysis['æ—¥ä»˜']).apply(lambda x: "ä¼‘æ—¥" if is_holiday_for_dow(x) else "å¹³æ—¥")
            logger.info("DOWã‚¿ãƒ–: 'å¹³æ—¥åˆ¤å®š'åˆ—ã‚’å‹•çš„ã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
        except ImportError:
            st.error("jpholidayãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¹³æ—¥/ä¼‘æ—¥ã®åˆ¤å®šãŒã§ãã¾ã›ã‚“ã€‚")
            return
        except Exception as e_hd:
            st.error(f"å¹³æ—¥åˆ¤å®šåˆ—ã®è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_hd}")
            logger.error(f"å¹³æ—¥åˆ¤å®šåˆ—ã®è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e_hd}", exc_info=True)
            return

    try:
        start_date_ts = pd.Timestamp(start_date)
        end_date_ts = pd.Timestamp(end_date)
    except Exception as e:
        st.error(f"âŒ æ¸¡ã•ã‚ŒãŸé–‹å§‹æ—¥ã¾ãŸã¯çµ‚äº†æ—¥ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
        logger.error(f"æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return

    period_days = (end_date_ts - start_date_ts).days + 1
    st.info(f"ğŸ“… **åˆ†ææœŸé–“ (çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨æ¸ˆ):** {start_date_ts.strftime('%Yå¹´%mæœˆ%dæ—¥')} ï½ {end_date_ts.strftime('%Yå¹´%mæœˆ%dæ—¥')} ï¼ˆ{period_days}æ—¥é–“ï¼‰")

    # =================================================================
    # âš™ï¸ æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æ è©³ç´°è¨­å®š (çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å°‚ç”¨)
    # =================================================================
    with st.expander("âš™ï¸ è¡¨ç¤ºãƒ»åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´", expanded=True):
        col_set1, col_set2 = st.columns(2)

        with col_set1:
            st.markdown("##### ğŸ“Š ãƒãƒ£ãƒ¼ãƒˆãƒ»é›†è¨ˆè¨­å®š")
            chart_metric_options = ['ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°', 'åœ¨é™¢æ‚£è€…æ•°']
            valid_chart_metrics = [m for m in chart_metric_options if m in df_analysis.columns]
            selected_metrics = st.multiselect(
                "ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºæŒ‡æ¨™:",
                valid_chart_metrics,
                default=[m for m in ['ç·å…¥é™¢æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°'] if m in valid_chart_metrics],
                key="dow_tab_chart_metrics_multiselect",
                help="ãƒãƒ£ãƒ¼ãƒˆã«è¡¨ç¤ºã™ã‚‹æ‚£è€…æ•°æŒ‡æ¨™ã‚’é¸æŠ"
            )

        with col_set2:
            aggregation_ui = st.selectbox(
                "é›†è¨ˆæ–¹æ³•:",
                ["æ›œæ—¥åˆ¥ å¹³å‡æ‚£è€…æ•°/æ—¥", "æ›œæ—¥åˆ¥ åˆè¨ˆæ‚£è€…æ•°"],
                index=0,
                key="dow_tab_aggregation_selectbox",
                help="ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆæ–¹æ³•ã‚’é¸æŠ"
            )
            metric_type_for_logic = 'average' if aggregation_ui == "æ›œæ—¥åˆ¥ å¹³å‡æ‚£è€…æ•°/æ—¥" else 'sum'

    # =================================================================
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼šæ›œæ—¥åˆ¥ãƒãƒ£ãƒ¼ãƒˆãƒ»ã‚µãƒãƒªãƒ¼ãƒ»ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    # =================================================================
    if not DOW_CHARTS_AVAILABLE:
        st.error("âŒ dow_charts.py ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return

    # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¯„å›²å…¨ä½“ã§ã®åˆ†æ
    st.success("ğŸ¥ **åˆ†æå¯¾è±¡:** çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¯„å›²å…¨ä½“")
    chart_unit_type_for_logic = 'ç—…é™¢å…¨ä½“'
    final_target_items_for_logic = []
    final_target_items_display_for_charts = ["çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¯„å›²"]

    st.markdown(f"### ğŸ“Š æ›œæ—¥åˆ¥ æ‚£è€…æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ ({aggregation_ui})")
    if selected_metrics:
        try:
            dow_data_for_chart = get_dow_data(
                df=df_analysis,
                unit_type=chart_unit_type_for_logic,
                target_items=final_target_items_for_logic,
                start_date=start_date_ts,
                end_date=end_date_ts,
                metric_type=metric_type_for_logic,
                patient_cols_to_analyze=selected_metrics
            )

            if dow_data_for_chart is not None and not dow_data_for_chart.empty:
                fig = create_dow_chart(
                    dow_data_melted=dow_data_for_chart,
                    unit_type=chart_unit_type_for_logic,
                    target_items=final_target_items_display_for_charts,
                    metric_type=metric_type_for_logic,
                    patient_cols_to_analyze=selected_metrics
                )
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("â„¹ï¸ æ›œæ—¥åˆ¥ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.info("â„¹ï¸ æ›œæ—¥åˆ¥ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.error(f"âŒ æ›œæ—¥åˆ¥ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            logger.error(f"æ›œæ—¥åˆ¥ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    else:
        st.info("â„¹ï¸ ãƒãƒ£ãƒ¼ãƒˆã«è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã€Œè¡¨ç¤ºãƒ»åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã€ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    # --- æ›œæ—¥åˆ¥è©³ç´°ã‚µãƒãƒªãƒ¼ ---
    st.markdown(f"### ğŸ“‹ æ›œæ—¥åˆ¥ è©³ç´°ã‚µãƒãƒªãƒ¼ ({aggregation_ui})")
    
    try:
        if calculate_dow_summary:
            summary_df_from_calc = calculate_dow_summary(
                df=df_analysis,
                start_date=start_date_ts,
                end_date=end_date_ts,
                group_by_column=None,  # å…¨ä½“é›†è¨ˆã®ãŸã‚None
                target_items=final_target_items_for_logic
            )
            if summary_df_from_calc is not None and not summary_df_from_calc.empty:
                display_summary_df = summary_df_from_calc.copy()

                cols_to_show = ['æ›œæ—¥å', 'é›†è¨ˆæ—¥æ•°']
                fmt = {'é›†è¨ˆæ—¥æ•°': "{:.0f}"}
                base_metrics_summary = ['å…¥é™¢æ‚£è€…æ•°', 'ç·Šæ€¥å…¥é™¢æ‚£è€…æ•°', 'ç·å…¥é™¢æ‚£è€…æ•°', 'é€€é™¢æ‚£è€…æ•°', 'æ­»äº¡æ‚£è€…æ•°', 'ç·é€€é™¢æ‚£è€…æ•°', 'åœ¨é™¢æ‚£è€…æ•°']

                if metric_type_for_logic == 'average':
                    for bm in base_metrics_summary:
                        col_avg = f"å¹³å‡{bm}"
                        if col_avg in display_summary_df.columns:
                            cols_to_show.append(col_avg); fmt[col_avg] = "{:.1f}"
                else: # sum
                    for bm in base_metrics_summary:
                        col_sum = f"{bm}åˆè¨ˆ"
                        if col_sum in display_summary_df.columns:
                            cols_to_show.append(col_sum); fmt[col_sum] = "{:.0f}"
                
                for rate_col in ['ç·Šæ€¥å…¥é™¢ç‡', 'æ­»äº¡é€€é™¢ç‡']:
                    if rate_col in display_summary_df.columns:
                        cols_to_show.append(rate_col); fmt[rate_col] = "{:.1f}%"
                
                cols_to_show_existing = [c for c in cols_to_show if c in display_summary_df.columns]

                if cols_to_show_existing and len(cols_to_show_existing) > 2:
                    st.dataframe(
                        display_summary_df[cols_to_show_existing].style.format(fmt, na_rep="-"),
                        height=min(len(display_summary_df) * 38 + 40, 600)
                    )
                    csv_bytes = display_summary_df[cols_to_show_existing].to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“Š ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes,
                        file_name=f"æ›œæ—¥åˆ¥ã‚µãƒãƒªãƒ¼_çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç¯„å›²_{start_date_ts.strftime('%Y%m%d')}-{end_date_ts.strftime('%Y%m%d')}.csv",
                        mime='text/csv', key="dow_tab_csv_summary_download"
                    )
                else:
                    st.info("â„¹ï¸ è¡¨ç¤ºã™ã‚‹ã‚µãƒãƒªãƒ¼æŒ‡æ¨™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.info("â„¹ï¸ æ›œæ—¥åˆ¥ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("âš ï¸ ã‚µãƒãƒªãƒ¼è¨ˆç®—é–¢æ•° (calculate_dow_summary) ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.error(f"âŒ æ›œæ—¥åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logger.error(f"æ›œæ—¥åˆ¥ã‚µãƒãƒªãƒ¼è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

    # --- åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆã¨å‚¾å‘ ---
    st.markdown("### ğŸ’¡ åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆã¨å‚¾å‘")
    if 'summary_df_from_calc' in locals() and summary_df_from_calc is not None and not summary_df_from_calc.empty:
        insights_dow = {"weekday_pattern": [], "general": []}
        
        # å¹³æ—¥ vs é€±æœ«ã®æ¯”è¼ƒ
        metric_for_insight = "ç·å…¥é™¢æ‚£è€…æ•°"
        avg_metric_col = f"å¹³å‡{metric_for_insight}"
        sum_metric_col = f"{metric_for_insight}åˆè¨ˆ"
        
        col_to_use_for_insight = None
        if metric_type_for_logic == 'average' and avg_metric_col in summary_df_from_calc.columns:
            col_to_use_for_insight = avg_metric_col
        elif metric_type_for_logic == 'sum' and sum_metric_col in summary_df_from_calc.columns:
            col_to_use_for_insight = sum_metric_col
        
        if col_to_use_for_insight:
            overall_summary_dow = summary_df_from_calc.groupby('æ›œæ—¥å', observed=False)[col_to_use_for_insight].sum().reset_index()
            if not overall_summary_dow.empty:
                max_day_insight = overall_summary_dow.loc[overall_summary_dow[col_to_use_for_insight].idxmax()]
                min_day_insight = overall_summary_dow.loc[overall_summary_dow[col_to_use_for_insight].idxmin()]
                insights_dow["weekday_pattern"].append(f"{metric_for_insight}ã¯**{max_day_insight['æ›œæ—¥å']}**ãŒæœ€ã‚‚å¤šãã€**{min_day_insight['æ›œæ—¥å']}**ãŒæœ€ã‚‚å°‘ãªã„å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")

        if insights_dow["weekday_pattern"] or insights_dow["general"]:
            st.markdown("<div class='info-card'>", unsafe_allow_html=True)
            st.markdown("#### ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆ")
            for section, ins_list in insights_dow.items():
                for ins in ins_list: 
                    st.markdown(f"- {ins}")
            st.markdown("</div>", unsafe_allow_html=True)
        else:
            st.info("â„¹ï¸ åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("â„¹ï¸ åˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    logger.info("æ›œæ—¥åˆ¥å…¥é€€é™¢åˆ†æã‚¿ãƒ–ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")